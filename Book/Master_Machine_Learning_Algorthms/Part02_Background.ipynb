{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TienNguyen0712/Data-Science/blob/main/Book/Master_Machine_Learning_Algorthms/Part02_Background.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part II: Background**"
      ],
      "metadata": {
        "id": "peg8nghPUZ5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chapter 2: Nói về dữ liệu trong Học máy **(Machine Learning)****"
      ],
      "metadata": {
        "id": "rbDd9XelN-jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phần này để chúng ta bàn luận về những điều cơ bản nhât trong học máy như:\n",
        "1. Cách biểu diễn dữ liệu hay tổ chức dữ liệu thành các hàng hay các cột\n",
        "2. Cách các thuật toán học máy liên kết dữ liệu đầu vào **(input)** đến **output**\n",
        "3. Các thuật toán tham số và phi tham số\n",
        "4. Học giám sát, không giám sá và bán giám sát\n",
        "5. Bias **(độ lệch)** và variance **(phương sai)**\n",
        "6. **Overfitting** và **Underfitting**   \n",
        "\n",
        "Dữ liệu là đóng vai trò quan trọng trong học máy. Trong chương này chúng ta sẽ tìm hiểu vè dữ liệu trong học máy cụ thể như:  \n",
        "* Thuật ngữ chung khi nói về dữ liệu\n",
        "* Thuật ngữ của thống kê và góc nhìn thống kê trong học máy\n",
        "* Thuật ngữ sử dụng trong khoa học máy tính đến với học máy"
      ],
      "metadata": {
        "id": "R7us4Bl2UZ8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1. Làm sao để nói về dữ liệu trong học máy**"
      ],
      "metadata": {
        "id": "nPFB6N0oUZ_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hãy nhìn vào một bảng dữu liệu cho trước ta nói rằng:\n",
        "* **Columns** (Cột): Mỗi cột được hiểu rằng chỉ chứa 1 kiểu dữ liệu duy nhât (chung độ do, chúng ý nghĩa với nhau, ...)\n",
        "* **Row** (Hàng): là các thực thể duy nhất hay những quan sát mà các cột miêu tả về thực thể hay quan sát đó, càng nhiều hàng thì sẽ có nhiều **(example)** để có thể giải quyết vấn đề của ta\n",
        "* **Cell**: là một giá trị duy nhất trong cột và hàng. Có thể là một số thực hay số nguyên thậm chí là phân loại"
      ],
      "metadata": {
        "id": "dNjULQNYUaCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2. Diễn tả theo thống kê**"
      ],
      "metadata": {
        "id": "4lni4rKGUaFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cho một hàm giả thuyết *(f)* là hàm để học của một mô hình học máy nào đó. Ta đưa vào *(input)* thứ mà ta dự đoán được chính là *(output)*\n",
        "\n",
        "\n",
        "> *Output = f(Input)*\n",
        "\n",
        "Tương tự cứ một **column** trong bảng dữ liệu thì ta sẽ xem là một **InputVariable** Tuy nhiên không phải lúc nào cột mà ta mong muốn cũng sẽ có đầy đủ điều đó cần ta phải dự đoán chúng hay có tên gọi khác chính là **OutputVariable**\n",
        "\n",
        "\n",
        "\n",
        "> *OutputVariable = f(InputVariable)*\n",
        "\n",
        "Nếu như ta có nhiều cột đầu vào thì sao?. Vậy thì chúng ta sẽ biểu diễn chúng dưới dạng **InputVector**\n",
        "\n",
        "> *Output = f(InputVector)*\n",
        "\n",
        "Hay trong thống kê ta sẽ nói **InputVariable** là biến không phụ thuộc **IndependentVariable** còn **OutputVariable** là **DependentVariable**. Điều này là bởi vì kết quả của giá trị dự đoán phụ thuộc vào hàm input hoặc các independent variable\n",
        "\n",
        "> *DependentVariable = f(IndependentVariables)*\n",
        "\n",
        "Ngoài ra mô tả dữ liệu cũng dùng các công thức ngắn gọn để biều diễn trong các thuật toán học máy.\n",
        "  * Các biến input được biểu diễn là *X* (đọc là capital *x*)\n",
        "  * Các output là *Y* (đọc là capital *y*)\n",
        "  \n",
        "> *Y = f(X)*\n",
        "\n",
        "Nếu chúng ta có nhiều hơn 1 input thông thường sẽ được biểu diễn dưới dạng input vecto và các column sẽ là các column trong vecto đó\n"
      ],
      "metadata": {
        "id": "pDmd1uBnUaIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3. Mô tả đối với Khoa học máy tính**"
      ],
      "metadata": {
        "id": "fQAV4EJmUaLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Với các nhà khoa học máy tính họ định nghĩa rằng **row** chính là một thực thể (giống như 1 người) hoặc một quan sát về một thực thể nào đó. **columns** cho **row** đó chính là những thuộc tính **(attribute)** mà quan sát đó có được. Khi áp dụng mô hinh để dự đoán chúng ta sẽ dựa vào thuộc tính đầu vào **(InputAttribute)** và đưa ra thuộc tính đầu ra **(OutputAttribute)**\n",
        "\n",
        "> *OutputAttribute = Program(InputAttributes)*\n",
        "\n",
        "Một cái tên khác cho **columns** chính là đặc trưng **(feartures)** được sử dụng cùng lý do như với **attribute** nơi mà một **feature** được xem như là một mấu chốt cho những quan sát thu được. Đây là tên gọi phổ biến khi làm việc với dữ liẹu nơi mà **features** phải được tìm hiểu sâu, biến đồi từ dữ liệu ban đầu **(raw data)** để xây dựng 1 quan sát. Chẳng hạn như hình ảnh, âm thanh, video\n",
        "\n",
        "> *Ouput = Program(InputFeatures)*\n",
        "\n",
        "Một tên gọi khác nữa cho **row of data** hay một quan sát chính là trường hợp **(instance)**. Sử dụng tên này là bởi vì một **row** được xem xét như là 1 **single example** hoặc **single instance** để thu được 1 quan sát mới cho vấn đề đặt ra\n",
        "\n",
        "> *Prediction = Program(Instance)*\n",
        "\n"
      ],
      "metadata": {
        "id": "z8Njrl11UaOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.4. Mô hình và thuật toán**"
      ],
      "metadata": {
        "id": "lKK0KZJFUaRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một vấn đề cần làm rõ đó chính là mô hình và thuật toán chính là hai phạm trù riêng biệt với nhau:\n",
        "* **Mô hình** chính là cách để chúng ta diễn tả cách học từ dữ liệu\n",
        "* **Thuật toán** chính là quá trình hay các bước học tập của chúng\n",
        "\n",
        "> *Model = Algorithm(Data)*\n",
        "\n"
      ],
      "metadata": {
        "id": "dhEG8oA8UaUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.5. Tóm tắt**"
      ],
      "metadata": {
        "id": "hfxrk_4gUaXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong phần 2 này ta đã được tìm hiểu về các thuật ngữ chính được sử dụng trong **Machine Learning**\n",
        "* Bắt đàu từ các khái niệm cơ bản nhất trong một tập dữ liệu có **rows**, **columns**, **cells**\n",
        "* Định nghĩa **input** và **output** theo cách hiểu của thống kê như *X* hay *sY*\n",
        "* Định nghĩa theo khoa học máy tính **attribute**, **features** và **instance**\n",
        "* Cuối cùng là phân biệt về mô hình **(model)** và thuật toán **(algorithms)** rằng mô hình được hình thành do các bước mà thuật toán tạo ra *(quá trình học)* từ dữ liệu huấn luyện"
      ],
      "metadata": {
        "id": "tsK4p34tUaZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chapter 3: Thuật toán học cách kết nối Input để tạo thành Output**"
      ],
      "metadata": {
        "id": "q15yqahzUach"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Làm sao mà các thuật toán học hoạt động?. Có nguyên tắc chung nào làm nền tảng cho các mô hình học có giám sát trong khía cạnh dự đoán hay không?. Trong phần này ta sẽ tìm hiểu xem công việc thật sự của các mô hình học máy bằng cách hiểu những nguyên tăc của tất cả các thuật toán\n",
        "1. The mapping của vấn đề mà tất cả các thuật toán học có giám sát nhắm vào để giải quyết\n",
        "2. Lĩnh vực con của máy học được gọi là mô hình dự đoán **(predictive\n",
        "modeling.)**\n",
        "3. Sự khác nhau giữa các thuật toán máy học diễn giải nhiễu bước **(strategies)** cho việc học trong hàm map **(mapping function)**"
      ],
      "metadata": {
        "id": "SA3MTeQEPSYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. Hàm học**"
      ],
      "metadata": {
        "id": "9AQ2PlcRPSVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các thuật toán máy học diễn ta một hàm học mục tiêu **(a target function)** *(f)* là maps tốt nhất để có thể đưa **input variables** *(X)* và tạo ra **output variable** *(Y)*\n",
        "\n",
        "> *Y = f(X)*\n",
        "\n",
        "Cũng một cách mô tả khác về việc dự đoán các yếu tố mới trong tương lai *(Y)* khi ta đưa một input mới *(X)*. Chúng ta sẽ không biết được hàm học *(f)* sẽ như thế nào?. Đó cũng chính là lí do mà error *(e)* sai số sẽ không phụ thuộc vào input data *(X)*\n",
        "\n",
        "> *Y = f(X) + e*\n"
      ],
      "metadata": {
        "id": "gYRDHre9aEmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Hàm học để thực hiện dự đoán**\n"
      ],
      "metadata": {
        "id": "GBFVZF5_PSSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một cách thông thường cách học của học mày là mapping *Y = f(X)* để dự đoán một biến *Y* từ một biến đầu vào *X* mới. Điều này được gọi là dự đoán mô hình hoặc dự đoán phân tích và mục đích của chúng ta sẽ là độ chính xác tối ưu nhất có thể    \n",
        "\n",
        "Chúng ta không quá hứng thú về hình dạng và form của một hàm *(f)* mà chúng ta học, ngoài chỉ khi chúng đưa ra dự đoán chính xác. Tuy nhiên chúng ta có thể mapping *Y = f(X)* để học nhiều về mối quan hệ giữa dữ liệu và đây được gọi là suy luận thống kê. Nếu đây là mục đích chúng ta cần phải sử dụng những phương pháp chuẩn hoá **(simpler methods)** và hiểu rõ các giá trị **(value understanding)** để đưa một dự đoán chuẩn xác\n",
        "\n",
        "Khi chúng ta học về *(f)* chúng ta cần phải ước tính hình dạng của hàm như thế nào từ dữ liệu có sẵn. Tuy nhiên những ước trính này có thể sai. Không phải lúc nào các chuẩn đoán cũng hoàn hảo đối với các giả thuyết cơ bản **(underlying hypothetical)** để tạo ta *Y* từ *X*. Phần lớn thời gian áp dụng các học máy là cải thiện các đánh giá dựa trên các hàm cơ bản và cúng phải cải thiện hiệu xuất của các dự đoán được tạo bởi model"
      ],
      "metadata": {
        "id": "Mjms18cbb7gL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3. Kỹ thuật (Techniques) cho hàm học**"
      ],
      "metadata": {
        "id": "BzrkUNePPSPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thuật toán học máy có kỹ thật hướng đến các hàm mục tiêu **(target function)** để dự đoán biến *output* dựa trên biến *input*. Diễn tả sự khác biệt giữa các giả định khác nhau về hình dạng của hàm học, bất kể là tuyến tính *(linear)* hoặc không tuyến tính *(nonlinear)*\n",
        "\n",
        "Các thuật toán học máy khác nhau thực hiện các giả định khác nhau về hình dạng và cấu trúc cùa hàm và làm sao để tối ưu hoá tốt nhất để xấp xỉ nó. Điều này là lý do vì sao ta phải sử dụng nhiều thuật toán khác nhau sao cho phù hợp với các vấn đề học máy. Bởi lẽ chúng ta sẽ không biết được rằng cấu trúc nào sẽ hợp lý với các con số mà chúng ta xấp xỉ"
      ],
      "metadata": {
        "id": "DG3PF-TpPSME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4. Tóm tắt**"
      ],
      "metadata": {
        "id": "FXfg47orPSIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong chương này chúng ta sẽ tìm hiểu các nguyên tắc cơ bản để diễn tả một thực thể cho tất cả các thuật toán máy học để dự đoán cho mô hinh dự đoán\n",
        "* Ta đã biết được rằng thuật toán học máy thực hiện ước lượng các hàm map (mapping function) *(f)* sinh ra *output* *(Y)* từ *input* *(X)* , hoặc *Y = f(X)*\n",
        "* Ta cũng đã biết dược rằng những thuật toán học máy khác nhau sẽ đưa ra các giả định khác nhau về hình dáng của hàm cơ bản\n",
        "* Khi chúng ta không biết các hàm mục tiêu *target function* nào là tốt nhát. chúng ta phải sử dụng nhiều thuật toán khác để tìm thuật toán nào là tốt nhất"
      ],
      "metadata": {
        "id": "9dRH-qPPPSEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 4: Thuật toán học máy tham số và phi tham số**"
      ],
      "metadata": {
        "id": "3gYSxQDsPSAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thế nào là một mô hình học máy tham số và chúng khác nhau như thế nào với mô hình học máy phi tham số?. Trong chương này chúng ta sẽ tìm hiểu sự khác nhau giữa thuật toán tham số và phi tham số. Những ý chính như:\n",
        "* Thuật toán học máy tham số đơn giản trong việc map để hình dung **form** của các chức năng\n",
        "* Thuật toán học máy phi tham số có thể học bằng cách map bất kì *input* nào dể tạo thành *output*\n",
        "* Tất cả những thuật toán được chia theo các nhóm tham số hoặc phi tham số"
      ],
      "metadata": {
        "id": "fTo8kwdPPR88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. Thuật toán học máy tham số**"
      ],
      "metadata": {
        "id": "L-wEZ0cRPR5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giả định mà ta đặt ra có thể đơn giản hoá quá trình học, những cũng có thể giới hạn những gì có thể được học. Thuật toán đơn giản hoá các hàm đề tìm thấy một quy chuẩn công thức duy nhất gọi là thuật toán học máy tham số **(machine learning\n",
        "algorithms.)**\n",
        "\n",
        "Mô hình học máy tóm tắt dữ liệu thành 1 tập hợp tham số với kích thước cố định (các số không phụ thuộc trong tập dữ liệu huán luyện) được gọi là mô hình tham số **(parametric model.)**. Việc lượng dữ liệu chúng ta có bao nhiêu là không đáng kể, chúng sẽ không thay đổi cách thức bao nhièu tham số mà mô hình cần\n",
        "\n",
        "Một thuật toán bao gồm 2 bước\n",
        "1. Lựa chọn **form** của hàm\n",
        "2. Học các hệ số chung cho **function** từ dữ liệu huấn luyện\n",
        "\n",
        "Một cách đơn giản để có thể hiểu **form** của hàm mapping là một **đường thằng**\n",
        "\n",
        "> B0 + B1 x X1 + B2 x X2 = 0  *(Hàm tuyến tính là dường thằng)*\n",
        "\n",
        "Trong đó *B0*, *B1* và *B2* chính là hệ số **(coefficients)** của đường thằng nhằm kiểm soát vùng chặn và độ dốc, và *X1* và *X2* chính là 2 *input* đầu vào. Với dạng đường thằng thì sẽ làm đơn giản hoá quá trình của hàm học. Thứ ta cần làm chính là gỉa định các *coefficients* của phương trình đưởng thằng nhằm tạo ra một mô hình dự đoán cho vấn đề\n",
        "\n",
        "Thông thường dạng của một hàm được gọi là tuyến tính *linear* bao gồm *input* và các mô hình học máy tham cũng được gọi là mô hình học máy tuyến tính *linear machine learning algorithms.*. Tuy nhiên các hàm định nghĩa không phải lúc nào cũng có dạng là một đường thẳng hoàn toàn. Điều đó chúng ta cần phải thay đổi dữ liệu một chút để có thể hoạt động một cách chuẩn xác. Hoặc nếu không phải là một đường thằng thì những giả định sẽ sai và sẽ đưa ra kết quẩ không thực sự đúng\n",
        "\n",
        "* Một số các thuạt toán máy học tham số là:\n",
        "  * Logistic Regression **(Hồi quy Logistic)**\n",
        "  * Linear Discriminant Analysis\n",
        "  * Perceptron\n",
        "* Ưu điểm của thuật toán\n",
        "  * **Simpler (Đơn giản)**: Chúng dễ hiểu, và có thể diễn dải kết quả một cách dễ dàng\n",
        "  * **Speed (Tốc độ)**: Học rất nhanh\n",
        "  * **Less Data (Ít dữ liệu)**: Không cần phải có quá nhiều dữ liệu và những thuật toán này có thể hoạt động tốt mặc dù việc khớp **fit** với dữu liệu không hoàn hảo\n",
        "* Hạn chế của thuận toán\n",
        "  * **Bị hạn chế (Constrained)**: Việc lựa chọn *function* chung rất khó\n",
        "  * **Độ phức tạp bị hạn chế (Limited Complexity)**: Chỉ phù hợp với các vấn đề đơn giản\n",
        "  * **Poor Fit**: Không quá hợp với các bài toán ánh xạ cơ bản"
      ],
      "metadata": {
        "id": "HxfFMC1KxUgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2. Thuật toán học máy phi tham số**"
      ],
      "metadata": {
        "id": "8p0wKVGaPR2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thuật toán không quá tập trung vào việc đưa ra cá hàm giả thuyết (các công thức chung) được gọi là thuật toán học máy phi tham số **(Nonparametric machine learning algorithms)**. Bằng việc không tạo ra các công thức chúng có thể học theo nhiều *function* khác nhau từ tập *training data*\n",
        "\n",
        "Thuật toán này được sử dụng khi có quá nhiều *data* không được biết trước và khi không muôn lo lắng quá nhiều về việc lựa chọn đúng *features*\n",
        "\n",
        "Phương thức phi tham số tìm cách *fit* với *training data*, đồng thời duy trì một khả năng khái quát với dữ liệu chưa biết. Tóm lại chúng *fit* với một dữ liệu lớn thông qua nhiều *function* khác nhau. Một cách dễ hiểu như thuật toán **KNN** sẽ không dựa vào công thức mà sẽ k điểm giống nhât để dưa ra dự đoán tức điểm nào gần điểm k nhất thì sẽ được xem như có chung một *output*\n",
        "* Một số các thuật toán học máy phi tham số là:\n",
        "  * Decision Trees **(Cây quyết định)**\n",
        "  * Naive Bayes\n",
        "  * Support Vector Machine **(SVM)**\n",
        "  * Neural Networks **(Mạng Nơ-Ron)**\n",
        "* Ưu điểm của thuật toán phi tham số:\n",
        "  * **Flexibility (Tính linh hoạt):** có khả năng *fit* với nhiều *functional forms* khác nhau\n",
        "  * **Power (Độ mạnh)**: Không có giả định\n",
        "  * **Performance (Hiệu suất)**: Có mô hình dự đoán kết quả cao\n",
        "* Hạn chế của mô hình học máy phi tham số:\n",
        "  * **More Data (Nhiều dữ liệu)**: Mô hình đòi hòi phải có nhiều dữ liệu để có thể *map* với *function*\n",
        "  * **Slower (Chậm hơn)**: Càng nhiều dữ liệu để *train* tốc độ để giải quyết bài toán càng chậm do sử dụng rất nhiều tham số\n",
        "  * **Overfitting (Quá khớp)**: Nếu điều khiển thay đổi các thông số khả nặng bị *overfit* càng cao"
      ],
      "metadata": {
        "id": "itrZU9zQPRyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.3. Tóm tắt**"
      ],
      "metadata": {
        "id": "YI1QtwuuPRvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong phần 4 chúng ta đã có thể phân biệt được rằng sự khác nhau giứa các thuật toán máy học tham số và phi tham số:\n",
        "* Phương thức học tham số tạo ra một giả định lớn **(công thức)** để có thể *map* *input* để tạo ra một *output*, và tốc độ *train* rất nhanh yêu cầu ít dữ liệu, không đa dạng\n",
        "* Phương thức học phi tham số tạo ra rất ít hoặc không có giả định cho một *target function* và yêu cầu một lượng lớn dữ liệu, có tốc độ *train* chậm và có nhiều mô hình hoạt hơn tuy nhiên kết quả có thể bị *overfitting*"
      ],
      "metadata": {
        "id": "Y6aWJ0FhPRrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chapter 5: Học giám sát, không giám sắt và bán giám sát**"
      ],
      "metadata": {
        "id": "27OEo04MPRo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong học máy việc học các thuật toán có nhiều kiểu khác nhau và chúng học như thế nào trong chương này chúng ta sẽ tìm hiểu việc mà các thuật toán học máy hoạt động như thế nào cụ thể nhưu sau:\n",
        "* Về vấn đề học của thuật toán giám sát phân loại **(classification)** và hồi quy **(regression)**\n",
        "* Vấn đề học của thuật toán không giám sát phân cụm **(clustering)** và kết hợp **(association)**\n",
        "* Các ví dụ về vấn đề học giám sát và không giám sát"
      ],
      "metadata": {
        "id": "NPX9EgHSPRlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.1. Học máy giám sát**"
      ],
      "metadata": {
        "id": "pCX4z70HPRib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Học giám sát là khi ta đưa vào một *input (X)* để đưa ra một *output (Y)* thông qua một thuật toán *(mapping function)*\n",
        "\n",
        "> *Y = f(X)*\n",
        "\n",
        "Mục đích là khi chúng ta đã xấp xỉ xác định một *mapping function* khi đưa một *input (X)* mới vào chúng có thể dự đoán một *output (Y)* cho dữ liệu đó. Việc gọi có giám sát tức chính là miêu tả cho quá trình học của thuật toán từ tập dữ liệu huấn luyện cho ra một *ouput* mới mà chúng ta đã biết trước kết quả chúng sẽ lặp đi lặp lại cho đến khi kết quả dự đoán gần đúng so với kết quả mà ta biết trước. Việc học sẽ dừng lại nếu như thuật toán đạt đến một mức độ mà không thể cải thiện hiệu suất được nữa. Thuật toán có giám sát được chia làm hai loại *Classification* và *Regression*\n",
        "* **Classification**: Vấn đề phân loại vơi nhau khi *output* là biến phân loại *category* ví dụ như *dỏ* hay *đen* hoặc *tác động* hay *không tác động*\n",
        "* **Regression**: Vấn đề về tuyến tính khi *output* là một số thực như *chiều cao* hoặc *cân nặng*\n",
        "Nhiều thuật toán phổ biến được xây dựng dựa trên việc *phân loại* và *tuyến tính* bao gồm hệ thống gợi ý và dự đoán **time series** (chuỗi thời gian)\n",
        "* Một số thuật toán có giám sát phổ biến:\n",
        "  * **Linear Regression (Hồi quy tuyến tính)** cho vấn đề tuyến tính\n",
        "  * **Random Forest** cho vấn đề phân loại và tuyến tính\n",
        "  * **Support Vector Machine (SVM)** cho vấn đề phân loại"
      ],
      "metadata": {
        "id": "Y4KZlyIVPRfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2. Học không giám sát**"
      ],
      "metadata": {
        "id": "rirIHuKOPRca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Học không giám sát là khi ta chỉ có một *input (X)* và không có mối quan hệ nào với biến *ouput*. Mục đích của việc học không giám sát là để mô hình cho một cấu trúc xác định hoặc phân tán của dữ liệu khi ta tìm hiểu về dữ liệu   \n",
        "Gọi là học không giám sát khi ta không hề biết trước chính xác một *output*. Thuật toán sẽ làm việc với *input* nhiều hơn, ta sẽ phải tìm hiểu cấu trúc phù hợp với dự liệu. Không giám sát cũng chia là hai loại *clustering* và *association*\n",
        "* **Clustering**: Phân loại là khi ta muốn nhóm các dữ liệu có cùng tính chất với nhau ví dụ như phân cụm khách hàng theo thói quen mua sắm\n",
        "* **Association**: Kết hớp là khi ta muốn tìm kiếm một dữ liệu dựa vào một luật nào đó như một người muốn mua A thì sẽ có khả năng mua B\n",
        "* Nhiều thuật toán không giám sát phổ biến như:\n",
        "  * **K-Means**: cho vấn đề phân cụm\n",
        "  * **Apriori**: cho vấn đề về kết hợp xu hướng\n",
        "  "
      ],
      "metadata": {
        "id": "RusWAmqbPRWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.3. Học bán giám sát**"
      ],
      "metadata": {
        "id": "wPpdoFwePRS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sử dụng khi ta có một lượng lớn dữ liệu *input (X)* những cũng chỉ có rất ít hoặc không có *label (Y)* có sự kết hợp giữa giám sát và cả không giám sát. Ví dụ như trong 1 kho lưu trữ ảnh chúng ta chỉ có ít bức ảnh *label (chó, mèo, người, ...)* và phần lớn thì không có *label*. Trong thực tế, thuật toán không được ưa chuộng, bởi vì chúng có kinh phí cao, thời gian thực hiện để gắn nhãn cho dữ liệu phải đòi hòi thuần thục về ảnh chiếu. Còn lại việc không gắn nhãn thì rẻ và rất dễ để có thể thu thập dữ liệu  \n",
        "Ta có sử dụng thuật toán không giám sát để có thể khai phá và học về các cấu trúc trong *input*. Ta cũng có thể sử dụng thuật toán có giám sát để có thể dự đoán cho một dữ liệu không được gắn nhãn, sau đó quay lại thuật toán giám sát để có thể *training* và sử dụng model để dự đoán cho một dữ liệu mới chưa biét\n"
      ],
      "metadata": {
        "id": "KiVvPKI7PRPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.4. Tóm tắt**"
      ],
      "metadata": {
        "id": "X5dZIuUwIvu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Supervised (Có giám sát)**: Tất cả dữ liệu được gắn nhãn *label* và thuật toán học để dự đoán *output* từ *input*\n",
        "* **Unsupervised (Không giám sát)**: Tất cả dữ liệu không được gắn nhãn *unlabel* và thuật toán học để tìm ra một cấu trúc chung cho từng biến *input*\n",
        "* **Semi-supervised (Bán giám sát)**: Nhiều dữu liệu không được gắn nhãn *unlabel* và có thể kết hợp với việc học giám sát và không giám sát\n"
      ],
      "metadata": {
        "id": "TRc98l7iIvSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chương 6: Bias-Variance (Thiên vị và Độ lệch chuẩn) và đánh đổi**"
      ],
      "metadata": {
        "id": "2kWVDPrUuf86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các thuật toán học máy có giám sát có thể học tốt như thế nào thông qua việc nhìn nhận các đánh đổi so với thiên vị và độ lệch phương sai. Trong chương này ta sẽ được biết rằng:\n",
        "* Tất cả các việc học sai **(error)** có thể được chia làm hai lỗi phổ biến lỗi thiên vị **(bias)** hoặc phương sai **(variance error)**\n",
        "* Các bias đề cập đến các giả định nhằm đơn giản việc học để có thể làm cho bài toán dễ dàng hơn để giải quyết\n",
        "* Tất cả những ứng dụng mô hình máy học cho việc dữ đoán có thể hiểu rõ nhất thông qua *framework* của *bias* và *variance*"
      ],
      "metadata": {
        "id": "yY3EQ1gGuq9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.1. Khái quát về Bias và Variance**"
      ],
      "metadata": {
        "id": "ZKgq4Ocxuq4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong thuật toán học có giám sát thuật toán sẽ thực hiện học từ *training data* mục đích của tất cả chúng chính là tìm ra hàm có thể *mapping* tối ưu nhất cho một dữ liệu được biểu diễn bằng *(f)* từ một biến *input (X)* để toạ ra một biến *output (Y)*. Hàm map thường gọi là *target function (hàm mục tiêu)* bởi lẽ chúng chính là thứ mà thuật toán học có giám sát đang *aims* để xấp xỉ. Giá trị sai số trong dự đoán mô hình chia làm 3 loại:\n",
        "* Bias Error (Lỗi thiên vị)\n",
        "* Variance Error (Lỗi phương sai)\n",
        "* Irreducible Error (Lỗi không thể gắn nhẵn)\n",
        "Đặc biệt với lỡi **Irreducible Error** chúng không thể giảm bất kể giá trị nào và cũng hỏi rằng thuật toán đã làm dược gì. Lỗi sai này đến từ trong phần giới thiệu sai số từ việc chọn *framing (khung)* cho vấn đề cần giải quyết như một biến \"ẩn\" rằng có thể map với input và thành output"
      ],
      "metadata": {
        "id": "r-rPpzeVuq1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.2. Lỗi thiên vị**"
      ],
      "metadata": {
        "id": "SXLdwUZmuqyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bias (Thiên vị)** được dỉnh nghĩa một cách đơn giản tạo ra bởi *model* để có thể làm cho *hàm mục tiêu (target function)* dễ hơn để có thể học, các thuật toán tham số có lượng bias-cao để có thể khiến cho mô hình học máy hiểu cũng như học một cách nhanh hơn tuy nhiên vẫn không mất dần quên đi. Lỗi các bác có một dự đoán nhỏ hơn cho việc tổ hợp. Tuy nhiên lại thật đơn giản để có thẻ định nghĩa bias của thuật toán\n",
        "* **Low Bias**: Có nhiều giả thuyết hay công thức về *form* của hàm mục tiêu\n",
        "* **High Bias**: Đưa ra ít nhận định cho form của hàm mục tiêu\n",
        "\n",
        "**Ví dụ về thuật toán có low-bias:**\n",
        "  * Decision Tree, KNN, SVM\n",
        "  \n",
        "**Ví dụ về thuật toán có high-bias:**\n",
        "  * Linear Regreesion, Linear Discriminant Analysis và Logistic Regression."
      ],
      "metadata": {
        "id": "z7_NnW7s0OMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.3. Lỗi phương sai**"
      ],
      "metadata": {
        "id": "A3W5sZfpuqwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Phương sai (Variance)** được hiểu là thước đo cho sự thay đổi của một biến mục tiếu. Hàm mục tiếu dưa trên từ training data bởi mô hình máy học. Tuy nhiên ta không nên thay đổi từ 1 đến nhiều thành phần của tệp dữ liệu huấn luyện, hiểu rõ rằng thuật toán nào để có thể hoạt động tốt đối với các dữ liệu khi lấy ra để có thể huấn luyện từ *input* để tạo thành *output* là điều cần ưu tiên. Các thuật toán học máy có phương sai cao thi khả năng ảnh hưởng cực kì mạnh đến với các con số trong dữ liẹu train, điều này cũng có nghĩa rằng sẽ ảnh hưởng cực kì mạnh mẽ từ tập train và có thể liên quan tới số lượng và kiểu của các dư liệu tham số được sử dụng trong các hàm *map*\n",
        "* **Low Variance**: Khuyến khích thay đổi một lượng nhỏ biến số trong dữ liệu training để ước lượng hàm mục tiêu *(target function)*\n",
        "* **Hight Variance**: Khuyến khích thay đổi một lượng lớn biến số trong dữ liệu training để ước lượng hàm mục tiêu *(target function)*\n",
        "\n",
        "Đối với các thuật toán phi tham số chúng có nhiều biến thể linh hoạt và có khả năng sinh ra một bias cao. Cho ví dụ cây quyết định có bias cao, nó sẽ cao hơn nếu những cây mà chúng ta xét không được dọn dẹp, cắt tỉa.\n",
        "\n",
        "**Ví dụ của low-variance**\n",
        "  * Linear Regression, Linear Discriminant Analysis và Logistic Regression.\n",
        "\n",
        "**Ví dụ của high-variance**\n",
        "  * Decision Trees, KNN và SVM"
      ],
      "metadata": {
        "id": "yS-4PaJjuqt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.4. Sự đánh đổi của Bias và Variance**"
      ],
      "metadata": {
        "id": "o6TzhBkLuqr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mục tiêu của bất kì phương thức học giám sát nào cũng là giảm thiểu lượng bias cũng như varince. Đồng thời thuật toán cũng nên có hiệu suất dưa ra các dự đoán đúng mang tính chính xác cao. Ta có thể theo dõi bên dưới:\n",
        "* Thuật toán tham số *(Parametric)* hoặc tuyến tính *(Linear)* thường sẽ có **high bias** nhưng lại có **low variance**\n",
        "\n",
        "* Thuật toán phi tham số *(Nonparametric)* hoặc phi tuyến tính *(Nonlinear)* thường sẽ có **low bias** nhưng lại có **high variance**\n",
        "\n",
        "Thuật toán tham số thường có những đối lập với sự cân bằng giữa bias và variance. Dưới là 2 ví dụ về sự đánh đổi giữa bias-variance\n",
        "\n",
        "* Thuật toán KNN có **low bias** và **high variance**, nhưng sự đánh đổi xảy ra khi ta gia tăng giá trị của k thứ mà sẽ gia tăng số lượng *neighbors* đồng thời cũng gia tăng nhiều giá trị dự đoán được và gia tăng bias của mô hình\n",
        "\n",
        "* Thuật toán SVM có **low bias** và **high variance**, nhưng sự đánh đổi xảy ra khi gia tăng hệ số C là tham số ảnh hưởng đến số lượng phạm vi của biên độ tạo vùng cho phép của *training data* thứ làm gia tăng bias nhưng lại giảm variance\n",
        "\n",
        "Không có cách nào để có thể thoát khỏi mối quan hệ giữa bias và variance trong học máy:\n",
        "* Gia tăng **bias** sẽ làm giảm **variance**\n",
        "* Giảm **bias** sẽ làm gia tăng **variance**\n",
        "\n",
        "Trên chính là sự đánh đổi giữa 2 cách thức kết hợp cùng thuật toán mà ta chọn và cách thức mà ta lựa chọn chúng để có thể tìm sự cân đối khác nhau hay đánh đổi mà ta có thể chấp nhận được trong bài toán của ta. Trong thực tế ta không thể tính toán chính xác bias hay variance error bỏi vì chúng ta không thực sự biết hàm tính toán giả định hoạt động như thế nào để tạo nền hàm mục tieu. Tuy nhiên, như một khung và không thể thay đổi, bias và variance được xem là những công cụ để có thể hiểu về hành vi của mô hình học máy trong việc gia tăng hiệu quả của học máy"
      ],
      "metadata": {
        "id": "ARbF09M7uqpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.5. Tóm tắt**"
      ],
      "metadata": {
        "id": "uB9tUAMwuqnI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chương này ta đã khám phá về bias và variance\n",
        "\n",
        "* **Bias** đơn giản hoá các giả định được đưa ra để mô hình có thể tạo một hàm mục tiêu dễ dàng hơn trong việc xấp xỉ\n",
        "* **Variance** lượng dữ liệuh tham số có thể bị thay đổi khi ta đưa một *training data* khác vào hàm mục tiêu\n",
        "* Sự đánh đổi giữa Bias và Variance"
      ],
      "metadata": {
        "id": "-rCX9MCLuqlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chương 7:  Overfitting và Underfitting**"
      ],
      "metadata": {
        "id": "TYABThVpuqdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một trong những điều khiến cho mô hình học máy có xu hướng hoạt động kém là do việc *overfitting* hay *underfitting* trong chương này ta sẽ tìm hiểu xem những khái niệm tổng quát trong máy học và những vấn đề về *overfitting* và *underfitting*. Sau khi đọc xong chương này ta sẽ tìm hiểu cụ thể như:\n",
        "* *Overfitting* chính là việc thuật toán học máy của chúng ta học quá khớp với dữ liệu huấn luyện và không thể học tốt khi đưa vào một bộ dữ liệu mới\n",
        "* *Underfitting* là khi mà thuật toán của chúng ta không thể học được gì từ tập dữ liệu huấn luyện\n",
        "* *Overfitting* là một vấn đề cực kì phổ biến trong việc luyện tập và có thể giải quyết bằng cách sử dụng các phương thức *resampling* và *a held back* dữ liệu mang tính xác thực"
      ],
      "metadata": {
        "id": "-0S4JNy6uqXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.1. Tổng quát trong máy học**"
      ],
      "metadata": {
        "id": "zex2RDBcFdcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong máy học ta sẽ diễn tả quá trình học của hàm mục tiêu từ dữ liệu huấn luyện áp dụng theo cách thức quy nạp tức học các khái niệm chung từ những ví dụ mang kết quả mà các vấn đề học máy ghim vào để giải quyết. CHúng sẽ khác với diễn dịch cũng là một cách học khác (từ việc học từ những quy luật chung từ những ràng buộc được đặt ra từ trước)\n",
        "\n",
        "Tổng quát đề cập đến mức độ mà các khái niệm được máy học áp dụng vào các mẫu tốt như thế nào khi chúng chưa được tiếp xúc trước kia. Mục tiêu của một máy học tốt chính là có thể tổng quát từ dữ liệu huán luyện đến bất kì dữ liệu nào từ các mặt của vấn đề. Điều này có thể cho phép chúng là những dự đoán trong dữ liệu tương lai mà chúng chưa nhìn thấy trước kia.  Thuật ngữ dùng để chỉ về việc các thuật toán học và tổng quát đến với dữ liệu tốt như thế nào?. Chính là *overftting* và *underfitting*. Chúng chính là nguyên nhân làm cho hiệu suất của thuật toán học máy giảm dần"
      ],
      "metadata": {
        "id": "8pBboUtGFdZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.2. Khớp thống kê**"
      ],
      "metadata": {
        "id": "HHWATb5iFdWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong thống kê *fit* dựa vào việc xấp xỉ hàm mục tiêu tốt như thế nào. Đây là một tín hiệu tốt cho việc sử dụng máy học bởi vì học có giám sát thực hiện việc xấp xỉ những hàm *mapping* chưa biết ẩn danh từ dữ liệu *input* để tạo ra *output*\n",
        "\n",
        "Thống kê diễn tả một *goodness fit* là khi cách thức ta thực hiện xấp xỉ để tạo ta một hàm mục tiêu sẽ tốt như thế nào. Một số cách rất hữu ích cho học máy, nhưng cần lưu ý việc lựa chọn phương pháp nào để có thể giả định nhằm biết được *form* của một hàm mục tiêu thông qua xấp xỉ. Nếu đã biết *form* hàm mục tiêu, chúng ta cần phải sử dụng trực tiếp để có thể làm dự đoán, thay vì việc cứ học các xấp xỉ từ mẫu chứa dữ liệu bị nhiễu"
      ],
      "metadata": {
        "id": "58xASzqIFdTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.3. Overfitting trong Học máy**"
      ],
      "metadata": {
        "id": "YP6LcGjtFdQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Overfitting* miêu tả việc mô hình học quá tốt đối với dữ liệu huán luyện, xảy ra khi một mô hình học chi tiết cá thành phần bao gồm các phần bị nhiễu trong dữ liệu huấn luyện điều này mang đến kết quả xấu khi ta đưa một dữ liệu mới vào để học. Có nghĩa các dữ liệu nhiễu hoặc biến động ngẫu nhiên trong tập dữ liệu huấn luyện đều được ghi nhớ và học giống như một khái niệm hoàn toàn của mô hình. Vấn đề là những khái niệm này không được áp dụng với dữ liệu mới và gây tác động xấu đến khả năng khái quát của mô hình\n",
        "\n",
        "*Overfitting* có khả năng cao xảy ra với thuật toán phi tham số và thuật toán không tuyến tính bởi những thuật toán này rất linh hoạt khi học một hàm mục tiêu. Như một số thuật toán phi tham số có thể bao gồm luôn cả tham số hoặc các kĩ thuật làm giảm và điều kiện làm sao để chi tiết một mô hình có thể được bỏ qua. Ví dụ cây quyết định có thẻ là một thuật toán tham số cũng có thể là một thuật toán phi tham số. Do dó *overfitting* khá cao. Ta cần phảt loại bỏ một số lá, rễ đồng thời cũng phải xử lý các dữ liệu bị nhiễu trong quá trình học của cây"
      ],
      "metadata": {
        "id": "6oAKUfhGQjR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.4. Underfitting trong Học máy**"
      ],
      "metadata": {
        "id": "1up1Yy8sFdMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Underfitting* được định nghĩa là khi mô hình đều không thể tổng quát được dữ liệu huán luyện cũng như dữ liệu mới. Sự *underfit* là khi mô hình không thể phù hợp và không rõ ràng điều này dẫn đến hiệu suất của mô hình sẽ giảm trong tập huấn luyện. Biện pháp đề khắc phục là ta tiếp tục huấn luyện và thay đổi thuật toán học máy. Là một khái niệm đối lập với *Overfitting*"
      ],
      "metadata": {
        "id": "EDuxw0JMVhD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.5. A good fit trong Học máy**"
      ],
      "metadata": {
        "id": "bzcUC-9zFdJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Một ý tưởng là ta lựa chọn một mô hình tại điểm *sweet* giữa *underfitting* và *overfitting* đây chính là mục đích của ta. tuy nhiên thực hiện là cực kì khó\n",
        "\n",
        "Để có thể hiểu được mục tiêu, chúng ta có thể nhìn vào hiệu suất của mô hình học máy trong suốt quá trình mà chúng học từ dữ liệu huấn luyện. Ta có thể *plot* quá trình học của cả dữ liệu huấn luyện và dữ liệu test mà ta giữ lại trong quá trình huấn luyện. Trong khoảng thời gian thuật toán học lỗi của mô hình trên tệp huấn luyện sẽ giảm vì thế mà các lỗi trên tập test cũng giảm. Nếu chúng ta huấn luyện quá nhiều hiệu suất của mô hình huấn luyện trên tập dữ liệu có thể giảm bởi vì mô hình đã bị overfitting mô hình đã học quá chi tiết bao gồm dữ liệu bị nhiều không liên quan đến tập huấn luyện. Lỗi của mô hình cũng sẽ tăng lại trong việc khái quát vấn đề\n",
        "\n",
        "khoảng *sweet* là điểm trước lỗi sai trên tập test và bắt đầu gia tăng nơi mà mô hình đạt được hiệu suất tốt nhất trên tập huấn luyện và tập dữ liệu test không thể thấy. Có hai phương pháp để có thể tìm thấy điểm *sweet*: **resampling methoda** (lựa chọn lại mẫu), **validation dataset** (dữ liệu kiểm thử trong quá tình huấn luyện)"
      ],
      "metadata": {
        "id": "jROPrpx8X-Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.6. Làm thế nào để giới hạn khoảng Overfitting**"
      ],
      "metadata": {
        "id": "VyI7ahlMFdFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cả hai *underfitting* và *overfitting* đều làm giảm hiệu suất của mô hình nhưng xa hơn vấn đề phổ biến khi áp dụng mô hình thường là *overfitting*. Là bởi vì việc đánh giá mô hình trên tập huấn luyện sẽ khác với đánh giá mô hình kết quả chúng ta cần quan tâm chính xác, như làm thế noà để thuật toán có hiệu suất tốt đố với dữ liệu chưa biết. Có hai kĩ thuật quan trọng nhất khi đánh giá mô hình máy nhằm giảm lượng *overfitting*:\n",
        "1. Sử dụng kĩ thuật *resampling* ước lượng độ chính xác của mô hình\n",
        "2. Giữ lại tập *validation set* làm dữ liệu để kiểm thử khi huấn luyện\n",
        "\n",
        "Kỹ thuật *resampling* phổ biến nhất là **k-fold validatioon**. Cho phép huấn luyện và kiểm thừ mô hình k lần theo nhiều bảng nhỏ từ tập huán luyện xây dựng đánh giá của mô hình trên tập không nhìn thấy\n",
        "\n",
        "*Validation dataset* hiểu đơn giản là một bảng dữ liệu nhỏ dựa trên tập huấn luyện và ta giữ lại nhằm kiểm thử mô hình huấn luyện cho đến khi kết thúc dự án. Sau khi ta đã chọn và áp dụng thuật toán máy học vào tập huấn luyện ta có thể đánh giá mô hình máy học trên tệp *validation* để có thể đưa ra nhận xét cuối cùng về việc mô hình có thể hoạt động tốt với dữ liệu không biết hay không. Sử dụng **cross validation** là tiêu chuẩn vàng cho học máy nhằm ước lượng độ chính xác của mô hình khi áp dụng thuật toán vào dữ liệu chưa biết. Nếu ta có dữ liệu thì việc sử dụng *validation dataset* củng rất bổ ích\n"
      ],
      "metadata": {
        "id": "oBm2zkrOj9I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.7. Tóm tắt**"
      ],
      "metadata": {
        "id": "4EQsV-WTFdB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong chương này chúng ta đã học cách máy học có thể giải quyết ván đề bằng phương thức quy nạp. Ta cũng đã biết việc khái quát là mô tả phương thức học và áp dụng dữ liệu mới diễn ra tốt như thế nào. Cuối cùng ta đã học về thuật ngữ trong việc khái quát dữ liệu trong máy học như *overfitting* hay *underfitting*\n",
        "* *Overfitting*: Hiệu suất tốt trên tập huấn luyện nhưng không thể khái quát dữ liệu khác\n",
        "* *Underfitting* Hiệu suất kém trên tập huấn luyện và cả khái quát kém trên những dữ liệu khác\n",
        "\n",
        "Ta đã biết được nhũng lỗi sai của *overfitting* và *underfitting*"
      ],
      "metadata": {
        "id": "ikeE5Skvj9gs"
      }
    }
  ]
}