{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Chương 8: Cấp tốc về bảng Tính toán**"
      ],
      "metadata": {
        "id": "NRuzqqMI6Rg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chương này ta sẽ đi qua nhanh về các khái niệm, hàm chức năng trong Toán học. Cụ thể như:\n",
        "* Làm sao để thực hiện các phép tính toán học trong *spreadsheet*\n",
        "* Làm sao để sử dụng các hàm trong thống kê để mô tả dữ liệu\n",
        "* Làm sao để tạo các số ngẫu nhiên để sử dụng trong tập *test* kiểm thử\n",
        "\n",
        "Ta đã không quá xa lạ đối với đối tượng *spreadsheet* hay là bảng tính. Tất cả những hàm cơ bản được xử dụng trong bảng tính đều tương tự khi ta áp dụng trong nhiều chương trình khác như:\n",
        "* Excel\n",
        "* Libre\n",
        "* Google Sheets\n"
      ],
      "metadata": {
        "id": "YnLjq5uU6Rku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.1. Số học (Arithmetic)**"
      ],
      "metadata": {
        "id": "X7J1aT2m6RoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bắt đầu với thành phàn cơ bản nhất như việc điều hướng *bảng tính* và số học\n",
        "* Một *cell* có thể đánh giá một *phép tính hay công thức* thông qua dấu **(=)** và sau đó là các phép tính Ví dụ như **= 1 + 1** thì kết quả sẽ là **2**\n",
        "* Ta có thể sử dụng các hàm trên một *cell* như hàm **=SUM()** tính tống các phần tử số. Ví dụ như **=SUM(A1:F1)** cộng tất cả các phần tử số từ dòng A1 đến F1\n",
        "* Cũng có thể sử dụng hàm **=COUNT()** để có thể đếm các *cell* có dữ liệu (không null)\n",
        "* Có thể biểu diễn số mũ qua toán từ **^**. Ví dụ muốn biểu diễu **2 bình phương** thì ta có thể **=2^2**\n",
        "* Sử dụng hàm **=LOG()** để biểu diễn logarit và dùng **=SQRT()** để biểu diễn căn bậc\n",
        "* Ta có thể sử dụng hàm **EXP()** để tính hệ số *Ơ-clit* lấy ví dụ như **EXP(2)** sẽ biểu diễn cho *e^2*\n",
        "* Hay ta có thể suy ngược lại từ hệ số Ơ clit để suy ra số mũ dựa theo hàm **LN()**\n",
        "* Biểu diễn PI trong toán học sử dụng hàm **=PI()**"
      ],
      "metadata": {
        "id": "7goTmUP56RrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.2. Tóm tắt thống kê (Statistical Summaries)**"
      ],
      "metadata": {
        "id": "ubdc9Wyi6RuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong nhiều thuật toán học máy việc biết tóm tắt thống kê là cực kì quan trọng. Hãy đến với các hàm được sử dụng để tóm tắt thống kê dữ liệu *input* đầu vào:\n",
        "* Hàm **=AVERAGE()** để tính giá trị *mean (giá trị trung bình)* của dữ liệu\n",
        "* Sử dùng hàm **=MODE()** để tìm giá trị *mode (giá trị xuất hiện nhiều nhất)* của dữ liệu\n",
        "* Dùng hàm **=STDEV()** để tính toán *Statistical Summaries (độ lệch chuẩn)* thường tham chiếu qua kí hiệu *sigma*\n",
        "* Ta cũng có thể tính toán hệ số quan hệ **correlation (chính là điểm cân bằng giữa hai danh sách dữ liệu)** giữa hai danh sách dữ liệu số sử dụng **=PEARSON**"
      ],
      "metadata": {
        "id": "1ZCbcb4m6RxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.3. Số ngẫu nhiên**"
      ],
      "metadata": {
        "id": "Za2xQ5PS6R0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong quá trình đào tạo mô hình học máy ta cần sử dụng dữ liệu mẫu *sampling* và không bị trùng nhau. Điều đó khiến ta phải dự dụng số ngẫu nhiên\n",
        "\n",
        "* Sử dụng hàm **=RAND** để sinh số ngẫu nhiên từ 0 đến 1\n",
        "* Ta có thể tính các số ngẫu nhiên Gauss bằng hàm **NORMINV()** Nhiều thuật toán tuyến tính đều sử dụng phân phối *Gauss*. Ví dụ như **=NORMINV(RAND(), 10, 1)** sẽ tạo ra một dãy số ngẫu nhiên theo phân phối *Gauss* với *mean* của chúng là 10 và *a standard deviation* là 1"
      ],
      "metadata": {
        "id": "yY81g6Ej6R32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.4. Flow Control**"
      ],
      "metadata": {
        "id": "_72uHamc6R7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta có thể sử dụng hàm **=IF(điều kiện, mệnh đề 1, mệnh đề 2)** để thực hiện đặt điều kiện cho một hàng nếu \"điều kiện\" đúng thì mệnh đề 1 sẽ thực hiện và nếu sai thì mệnh đề 2 sẽ thực hiện"
      ],
      "metadata": {
        "id": "BNrv-VsZ6R-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.5. Tóm tắt**"
      ],
      "metadata": {
        "id": "wdRKr3ZA6SB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta đã biết được một số các hàm toán học đại số để thực hiện thap tác trên *bảng tính*\n",
        "* Làm sao để có thể diễn tả các hàm toán học với dữ liệu số trong bảng tính như hàm đếm, cộng, logarit và hệ số e\n",
        "* Làm sao để sử dụng các hàm thống kê để tính toán nhằm tóm tắt dữ liệu như mean, mode hay std\n",
        "* Làm sao để có thể tạo ra sự đồng nhất và số ngẫu nhiên Gauss để sử dụng trong *test data*"
      ],
      "metadata": {
        "id": "9YV-yE-v6SFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chương 9: Gradient Descent Trong Học Máy**"
      ],
      "metadata": {
        "id": "DFg25x5E6SIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tối ưu hoá là phần lớn nhất trong học máy. Nhiều thuật toán máy học lấy việc tối ưu hoá làm phần cốt lõi. Trong chương này chúng ta sẽ tìm hiểu thuật toán tối ưu đơn giản nhất để áp dụng với tất cả các thuật toán máy học:\n",
        "* Chúng ta sẽ học về thuật toán gradient descent thuật toán tối ưu\n",
        "* Làm sao để có thể sử dụng thuật toán gradient descent vào mô hình máy học\n",
        "* Làm sao để thuật toán gradient descent tính toán với một dữ liệu lớn\n",
        "* Mẹo để có thể luyện tập xây dựng thuật toán gradient descent"
      ],
      "metadata": {
        "id": "K-l7PYQJ6SLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.1. Gradient Descent**"
      ],
      "metadata": {
        "id": "aqW9ODGN6SOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Là một thuật toán tối ưu được sử dụng để tìm các giá trị tham số của hàm *(f)* có thể giới hạn khoảng giá trị của hàm chi phí *(cost)*. Thuật toán này được sử dụng nhiều nhất khi mà các tham số không thể dược tính toán theo phương pháp phân tích và phải được tìm kiếm bằng huật toán tối ưu"
      ],
      "metadata": {
        "id": "7yMkjIn96SSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.1.1. Intuition for Gradient Descent**"
      ],
      "metadata": {
        "id": "XYTt5qTS6SWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mục đích của *Gradient Descent* là thử nghiệm nhiều giá trị tham số khác nhau nhằm đánh giá các hàm chi phí và lựa chọn một tham số mới có thể làm giảm giá trị của hàm chi phí. Lặp lại quá trình này cho đến khi kết quả của hàm chi phí đạt mức gần nhỏ nhất"
      ],
      "metadata": {
        "id": "E_0aB2I-6SbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.1.2. Gradient Descent Procedure**"
      ],
      "metadata": {
        "id": "j3UvXiGG6Sdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thuật toán bắt đầu bằng một giá trị tham số giả định có thể là 0.0 hay một giá trị ngẫu nhiên rất nhỏ\n",
        "\n",
        "Các tham số được đư vào các hàm *f* nhằm dự đoán cũng như tính toán chi phí\n",
        "\n",
        "> *cost = f(hệ số)*    \n",
        "   *cost = evaluate(f(hệ số))*\n",
        "\n",
        "Tính toán đạo hàm của hàm chi phí. Ta cần biết được độ dốc vì thế mà chúng ta cũng cần được biét đạo hàm để có thể điều chỉnh tham số sao cho hàm chi phí đạt giá trị nhỏ nhất\n",
        "\n",
        "> *delta = đạo hàm (cost)*\n",
        "\n",
        "Trong quá trình nâng cáp giá trị tham số. Tham số tỉ lệ quá trình học *(alpha)* phải được chỉ định nhằm chỉ định số lượng thay đổi của tham số sau mỗi lần update\n",
        "\n",
        "> *Tham số = Tham số - (delta x alpha)*\n",
        "\n",
        "Quá trình này lặp đi lặp lại cho đến khi hệ số của hàm chi phí bằng 0 hoặc không thể cải thiện thêm về hàm chi phí. Đối với thuật toán đơn giản nhất chúng yêu cầu ta biết về gradient của hàm chi phí của ta hoặc một hàm mà ta có thể tối ưu."
      ],
      "metadata": {
        "id": "P2Ivh60B6SgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.2. Batch Gradient Descent**"
      ],
      "metadata": {
        "id": "iptxAYEt6Si_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mục đích của tát cả các thuật toán học máy là có thể ước lượng một hàm mục tiêu tốt nhất *(f)* mà có thể map với dữ liệu đàu vào *(X)* để tạo thành một hàm output *(Y)*. Điều này cũng giống với cả tuyến tính hay phân loại. Nhiều thuật toán học máy có những tham số đặc trưng cho thuật toán nhằm ước lượng một hàm mục tiêu *(f)*. Khác với thuật toán có cách diễn dãi và các tham số khác nhau, nhưng phần lớn chúng yêu cầu việc tối ưu để tìm một tham số sao cho két quả tối ưu nhất về hàm mục tiêu. Các ví dụ thường thấy là thuật toán Gradient Descent được sử dụng cho thuật toán Hồi quy và Logistic\n",
        "\n",
        "Những đánh giá theo những con số khác nhau đồng nghĩa với việc là các thuật toán fit với dữ liệu như thế nào. Một hàm mất mất bao gồm đánh giá các tham số của mô hình bằng cách tính toán các dự đoán cho một kết quả của tập huấn luyện và so sánh các dự đoán để đạt đến một output chính xác sau đó tính toán tổng hoặc trung bình sai sô (như Sum Squared Residuals hay SSR trong thuật toán hồi quy tuyến tính)\n",
        "\n",
        "Từ hàm chi phí ta có thể tính toán mỗi hệ số vì thế mà có thể nâng cấp xử dụng chính xác lại cái hệ số đã sử dụng trước đó. Chi phí được tính toán chojn một thuật toán trong suốt quá trình huấn luyện với mỗi đạo hàm của gradient. một sự lặp lại được gọi là 1 batch. Batch Gradient Descent là form thường thấy của thuật toán gradient\n",
        "\n",
        "Đây chinh là thuật toán Gradient Descent thuật toán của nó thực hiện sử dụng tất cả cảc dữ liệu huấn luyện x và lặp lại việc đạo hàm tất cả dữ liệu này khi có một dữ liệu mới"
      ],
      "metadata": {
        "id": "bscci1Pl6Sl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.3 Stochastic Gradient Descent**"
      ],
      "metadata": {
        "id": "BYcn4T-L6SpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent có thể hoạt động chậm đối với tệp dữ liệu lớn. Bời vì sau mỗi lần lặp của thuật toán *gradient descent* yêu cầu dự đoán cho mỗi *instance* trong một tệp dữ liệu huấn luyện, ta sẽ phải chơ một thời gian dài khi ta có một 100 ngìn *instance*. Điều này sinh ra một thuật toán *Stochastic Gradient Descent* được xem là tối ưu và hiệu quả hơn *Batch Gradient Descent*\n",
        "\n",
        "Bước đầu tiên của thuật toán đối với tập dữ liệu huán luyện là ngẫu nhiên. Điều này kết hợp giữa việc tính toán tham số vừa phải cập nhật. Bởi vì khi cập nhật tham số nhiều lần ta phải tính toán chúng qua tập huấn luyện nhiều lần, việc cập nhạt sẽ bị nhiễu, và lưu trữ ở nhièu nơi, nếu cập nhiều tham số nhiều lần qua các bước nhảy ngẫu nhiên ta có thể gặp lỗi\n",
        "\n",
        "Sự cập nhật các tham số giống với cách thức ở trên, nhưng hàm mất mát không phải cộng hay tính trung bình trên tập huấn luyện, thay vầo đó la tính toán chỉ trên một tập dữ liệu nhỏ. Việc học có thể sẽ nhanh hơn với *stochastic gradient descent* với dữ liệu huấn luyện và thưởng chỉ cần một con số nhỏ để có thể đủ tốt hay đạt một tham số nhât định\n",
        "\n",
        "Thực hiện việc đạo hàm mất mát dựa trên chỉ một điểm dữ liệu rồi cập nhật vào hàm tổng dưa trên đạo hàm này. Việc này được thực hiện nhiều lần với những điểm trên toàn bộ dữ liệu, sau đó lặp lại quá trình trên, thay vì duyệt toàn bộ dữ liệu thì ta chỉ duyệt 1 dữ liệu duy nhất thường là 10 epoch đầu tiên rồi cập nhật vào tập dữ liệu chính"
      ],
      "metadata": {
        "id": "GxOrRwI96Stg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.4. Mẹo khi sử dụng thuật toán Gradient Descent**"
      ],
      "metadata": {
        "id": "z71UTN3r__ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mục này nhằm miêu tả các kĩ thuyoocj và mẹo để có thể thuần thục các thuật toán Gradient Descent\n",
        "\n",
        "- **Biểu đồ hoá quá trình cập nhật của hàm chi phi qua thời gian**: Thu thập và plot các giá trị mất mát đã được tính qua mỗi lần lặp.Kỳ vọng cải thiện khả hiệu năng của thuật toán\n",
        "- **Tỷ lệ học**: Tỷ lệ học là một giá trị số thực nhỏ như là 0.001 hay 0.01. Thử nhiều tỷ lệ khác nhau để có thể thây được thuật toán hoạt động tốt nhất đối với con số nào\n",
        "- **Rescale Input**: Thuật toán sẽ đạt tới giá trị mất mát nhỏ nhất nhanh hơn khi hình dáng của hàm mất mát không quá lệch hay méo mó. Ta có thể thay đổi hình dạng bằng cách rescale tất cả những biến *input (x)* về cùn một khoảng như khoảng giữa 0 đến 1\n",
        "- **Ít lớp**: Thuật toán Stochastic gradient descent thường không cần quá nhiều 1 đến 10 lóp trong suốt quá trình huấn luyện để có thể đạt được một tham số tốt nhất\n",
        "- **Plot Mean Cost**: Cập nhật sau mỗi lần huấn luyện một *instance* trong bảng dữ liệu có thể xảy ra các kết quả bị nhiễu *plot giá trị trung bình của hàm mất mát* trong suốt cảc quá trinh khi sử dụng thuật toán stochastic gradient descent. Lấy giấ trị trung bình khoảng 10, 100, 1000 làn cập nhật có thể giúp ta biét hơn về quá trình xu hướng học của mô hình thuật toán"
      ],
      "metadata": {
        "id": "_gCsk97V6SwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.5. Tóm tắt**"
      ],
      "metadata": {
        "id": "AVCnb7UF6Szm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chương này nhằm giúp ta khám phá về thuật toán tối ưu Gradient Descent trong học máy:\n",
        "* Tối ưu hoá là một phần lớn trong học máy\n",
        "* Thuật toán Gradient descent là thuật toán đơn giản nhất trong việc tối ưu hoá và có thể sử dụng với nhiều thuật toán học máy\n",
        "* Batch gradient descent thực hiện tính toán đạo hàm của toàn bộ tập dữ liệu rồi sau đó cập nhật\n",
        "* Stochastic gradient descent thực hiện đạo hàm cho mỗi tập dữ liệu instance và cập nhập ngay lập tức\n"
      ],
      "metadata": {
        "id": "V_yC7p2V6S22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chương 10: Hồi quy tuyến tính (Linear Regression)**"
      ],
      "metadata": {
        "id": "2T_vtvZI6S6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression là một trong những thuật toán dễ hiểu và dễ tiếp cận nhất trong thống kê và học máy. Chương này ta sẽ khám phá:\n",
        "- Tại sao thuật toán Linear Regression lại xuất hiện trong cả thống kê và học máy\n",
        "- Những tên gọi trong Linear Regression cần biết\n",
        "- Biểu diễn và học các thuật toán để tạo mô hình Linear Regression\n",
        "- Làm sao để có thể fit dữ liệu của ta khi tạo mô hình sử dụng thuật toán Linear Regression"
      ],
      "metadata": {
        "id": "sh3GyDPn6S9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.1. Có phải Linear Regression đến từ thống kê?**"
      ],
      "metadata": {
        "id": "juEbbpWF6TAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trước khi đi sâu vào thuật toán, thì ta cần hỏi bản thân rằng. Tại sao ta phải tìm hiểu thuật toán. Nó có phải là công cụ đến từ thống kê?  \n",
        "Máy học, miêu tả là một *field* sinh ra bằng mô hình dự đoán với sai số nhỏ nhất hay đạt nhiều giá trị chính xác nhất có thể qua các hàm chi phí. Áp dụng thuật toán học máy ta sẽ mượn, tái sử dụng, dáp dụng thuật toán từ nhiểu *field* khác nhau bao gồm cả thống kê sử dụng từ đầu đến cuối của dự án  \n",
        "Như vậy dựa trên những giả thích trên ta có thể hiểu hồi quy tuyến tính được tạo ra dứa trên *field* thống kê, các mô hình học và hiểu dựa trên mối quan hệ giữa biến số đầu vào và đầu ra. Cả hai thuật toán trong thống kê và học máy.  "
      ],
      "metadata": {
        "id": "hQ-hJSMn6TEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.2. Nhiều tên gọi trong Linear Regression**\n",
        "Khi ta bắt đầu tìm hiểu thuật toán Linear Regression rằng thuật toán này đã xuất hiện từ rất lâu. Chúng được học tập theo nhiều tên gọi khác nhau mỗi tên gọi có sự mới\n",
        "Thuật toán Linear Regression là một mô hình tuyến tính thực hiện việc ước lượng mối quan hệ giưuax biên input với mối biến output. Tức biến output có thể được tính toán từ các kết hợp của các biến input. Khi chỉ có một biến input ta sẽ có một hàm hồi quy tuyến tính đơn giản, khi ta có nhiều biên input thì ta sẽ có hàm tuyến tính mang nhièu biến ứng với các biến đầu vào\n",
        "\n",
        "Các *techniques* có thể được sử dụng trong việc chuẩn bị hay huấn luyện mô hình tuyến tính từ dữ liệu. Phổ biến nhất thường được gọi là Ordinary Least Squares. Nó phổ biến với việc thưởng sử dụng mô hình chuẩn bị Ordinary Least Squares Linear Regression hay chỉ Least Squares\n",
        "Regression."
      ],
      "metadata": {
        "id": "NNedxRF36THR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.3. Biểu diễn mô hình Linear Regression**"
      ],
      "metadata": {
        "id": "7dUxIx8D6TKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression là một mô hình dễ tiếp cận vì chúng khá đơn giản. Biểu diễn chúng sẽ tuỳ theo sự kết hợp của các biến đầu vào trong tâp set với giải pháp cái mà có thể dự đoán output từ chúng. Và dữ liệu input và output phải là dữ liệu số (Numerical)\n",
        "\n",
        "Linear Regression thực hiện gán một scale cho mỗi giá trị input hay cột, gọi là một hệ số. Cách biểu diễn thường thấy là Beta. Cộng dần các giá trị để toạ thành môt hàm số là dường thằng trên mẳt phẳng 2 chiều rồi sau đó cộng với tự do thường được gọi là số chặn hay là hệ số bias. Ví dụ một hàm tuyến tính đơn giản với giá trị x là biến input và y là biến ouput\n",
        "\n",
        "> *y = B0 + B1 X x*\n",
        "\n",
        "Số chiều càng gia tăng nếu có có càng nhiều *input*. đoạn thằng thường được gọi là a plane or a hyper-plane. các hệ số tự do (B0, B1) là hệ số do mô hình tuyến tính tạo ra  \n",
        "\n",
        "Khi hệ số trở về 0, sẽ khiến biến đầu ra của ta cũng bằng 0 điều này sẽ loại bỏ giá trị của *output*"
      ],
      "metadata": {
        "id": "dlN284TMvg_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.4. Phương thức học Linear Regression Learning**"
      ],
      "metadata": {
        "id": "WWFKLXoJvji3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Có nhiều kĩ thuật các phương thức học khác nhau trong mô hình này cụ thể chúng ta sẽ tìm hiểu 4 kĩ thuật để chuẩn bị cho mô hình linear regression.\n",
        "1. **Mô hình Linear Regression đơn giản:** Khi ta có duy nhất một dữ liệu *input*, ta có thể sử dụng thống kê để có thể ước lượng các hệ số. Yêu cầu ta phải tính toán trước các hệ số trong thống kê như mean, std, hệ ố quan hệ, phương sai. Tât cả dữu liệu phải có giá trị thông qua và có thể tính toán được trong thống kê\n",
        "2. **Mô hình Ordinary Least Squares:** Khi ta có nhiều *input* ta có thể sử dụng Ordinary Least Squares để ước lượng giá trị của hệ số bằng cách giảm thiểu tổng bình phương của dữ liệu còn lai . Điều này nói rằng trên những diểm thuôc đường thằng là đường tuyến tính ta phải tính khoảng cách giữa những điểm đó sau đó bình phương rồi cộng bình phương sai số. Đây là số lượng mà thuật toán muốn giảm thiểu  \n",
        "Để tiếp cân thuật toán này ta phải biết đến các ma trận sau đố sử dụng các phép toán đại số tuyến tính để ước lượng các giá trị hệ số. Điều này cps nghãi tất cả dữ liệu phải có giá trị và ta phải có đủ bộ nhớ để fit và biểu diễn các phép toán ma trận  "
      ],
      "metadata": {
        "id": "iq1bLL4TvldM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o7vHqycGvnrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kCSkFZNLvnoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X9E5cGYuvnlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9FdVHkvavnhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7MF2qoqYvnd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AijWyxJqvnZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Tc9BcChlvnWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u185-T3avnRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CxAuxS5pvnNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IqPI2rlqvnKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FmKUh77HvnFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P7zX3EsHvlah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HaZZKtuhvlXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q6GfXe7SvlVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4wy57yRVvlSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NKWZn9LOvlJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lLK7nMz9vlxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AbTDrldFvkAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JBuVST6-vkRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mB3t3lNtvkk2"
      }
    }
  ]
}